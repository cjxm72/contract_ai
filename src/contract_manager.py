import asyncio
import json
import re
import sys
from pathlib import Path
from typing import Dict, Any, List

import requests
from loguru import logger

from util.PandocSettings import openai_settings
from model_manager import QwenModel


class ContractManager:
    def __init__(self):
        self.local_model = None
        self.model_mode = "online"
        self.temperature = 0.3
        self.max_tokens = openai_settings.max_tokens or 4048
        self.timeout = openai_settings.timeout_seconds if openai_settings.use_local_model else openai_settings.timeout
        self.max_rounds = 3  # ä¸šåŠ¡è§„åˆ™ï¼šæœ€å¤š3è½®è¡¥å……
        self.http_session = requests.Session()

        self._initialize_model_pipeline()
        self._load_contract_templates()

    def _initialize_model_pipeline(self):
        """æ ¹æ®é…ç½®åŠ è½½æœ¬åœ°æ¨¡å‹æˆ–å‡†å¤‡åœ¨çº¿é…ç½®"""
        self.temperature = openai_settings.temperature if hasattr(openai_settings, "temperature") else self.temperature
        self.max_tokens = openai_settings.max_tokens or self.max_tokens

        if openai_settings.use_local_model:
            self.local_model = QwenModel()
            if self.local_model.load_model():
                self.model_mode = "local"
                logger.info("âœ… ä½¿ç”¨æœ¬åœ°Qwenæ¨¡å‹è¿›è¡Œæ¨ç†")
                return
            logger.warning("âš ï¸ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåˆ‡æ¢ä¸ºåœ¨çº¿API")

        self.model_mode = "online"

    def _call_model(self, prompt: str, task: str) -> str:
        """æ ¹æ®å½“å‰æ¨¡å¼è°ƒç”¨æ¨¡å‹ï¼Œå¤±è´¥åè‡ªåŠ¨é‡è¯•æˆ–é™çº§"""
        last_error = None
        if self.model_mode == "local" and self.local_model and self.local_model.is_loaded():
            try:
                return self._call_local_model(prompt)
            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ æœ¬åœ°æ¨¡å‹æ‰§è¡Œ{task}å¤±è´¥ï¼Œé™çº§åˆ°åœ¨çº¿API: {e}")
                self.model_mode = "online"

        try:
            return self._call_online_model(prompt)
        except Exception as e:
            if last_error:
                logger.error(f"âŒ æœ¬åœ°ä¸åœ¨çº¿æ¨¡å‹å‡å¤±è´¥ï¼Œæœ¬åœ°é”™è¯¯: {last_error}")
            raise e

    def _call_local_model(self, prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ°Qwenæ¨¡å‹"""
        if not self.local_model or not self.local_model.is_loaded():
            raise RuntimeError("æœ¬åœ°æ¨¡å‹æœªåŠ è½½")

        model, tokenizer = self.local_model.get_model()
        if model is None or tokenizer is None:
            raise RuntimeError("æœ¬åœ°æ¨¡å‹ç»„ä»¶æœªå‡†å¤‡å¥½")

        inputs = tokenizer(prompt, return_tensors="pt")
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        output_ids = model.generate(
            **inputs,
            max_new_tokens=min(self.max_tokens, 1024),
            temperature=self.temperature,
            do_sample=True,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.pad_token_id
        )
        decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)
        if decoded.startswith(prompt):
            decoded = decoded[len(prompt):]
        return decoded.strip()

    def _call_online_model(self, prompt: str) -> str:
        """è°ƒç”¨åœ¨çº¿APIæ¨¡å‹"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {openai_settings.api_key}"
        }
        payload = {
            "model": openai_settings.model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": min(self.max_tokens, 4048),
            "temperature": self.temperature
        }

        retries = openai_settings.max_retries if hasattr(openai_settings, "max_retries") else 1

        for attempt in range(retries + 1):
            try:
                response = self.http_session.post(
                    f"{openai_settings.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=self.timeout
                )
                if response.status_code == 200:
                    data = response.json()
                    return data["choices"][0]["message"]["content"].strip()
                logger.warning(f"âš ï¸ åœ¨çº¿æ¨¡å‹è¯·æ±‚å¤±è´¥({attempt + 1}/{retries + 1}): {response.status_code} {response.text}")
            except Exception as exc:
                logger.warning(f"âš ï¸ åœ¨çº¿æ¨¡å‹è¯·æ±‚å¼‚å¸¸({attempt + 1}/{retries + 1}): {exc}")

        raise RuntimeError("åœ¨çº¿æ¨¡å‹è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")

    async def process_contract_interactive(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """äº¤äº’å¼å¤„ç†åˆåŒè¯·æ±‚ï¼ˆè¯­ä¹‰åˆ†æ â†’ å¤šè½®è¡¥å…… â†’ åˆåŒç”Ÿæˆï¼‰"""
        try:
            conversation_history: List[Dict[str, str]] = []
            user_notes: List[str] = []
            asked_questions: List[str] = []  # è®°å½•å·²æå‡ºçš„é—®é¢˜ï¼Œé¿å…é‡å¤
            info_complete = False
            analysis_prompt = self._prepare_initial_context(input_data, "", asked_questions, is_first_round=True)

            # ç¬¬0è½®ï¼šæ¥å—JSONï¼ŒAIåˆ†æå¹¶æé—®ï¼ˆå¿…é¡»è¾“å‡ºï¼‰
            print(f"\n{'=' * 60}")
            print("ğŸ¤– AIæ­£åœ¨æ‰§è¡Œè¯­ä¹‰çº§å®Œæ•´æ€§åˆ†æ...")
            print(f"{'=' * 60}")
            print(f"\nğŸ”„ ç¬¬ 0 è½®ï¼šåˆå§‹åˆ†æ")
            
            ai_response = await asyncio.to_thread(self._call_model, analysis_prompt, "analysis")
            ai_response = self._limit_text(ai_response, 300)
            info_complete = False  # ç¬¬0è½®å¼ºåˆ¶ä¸å®Œæ•´ï¼Œå¿…é¡»æé—®

            # æå–æœ¬æ¬¡æå‡ºçš„é—®é¢˜ï¼ŒåŠ å…¥è®°å¿†
            new_questions = self._extract_questions(ai_response)
            asked_questions.extend(new_questions)

            conversation_history.append({
                "role": "assistant",
                "content": ai_response,
                "name": "SemanticReviewer"
            })

            # ç¬¬0è½®å¿…é¡»è¾“å‡º
            print(f"\n{'=' * 60}")
            print("ğŸ¤– AIåˆ†æç»“æœï¼š")
            print(ai_response)
            print(f"{'=' * 60}")

            # ç¬¬0è½®ç”¨æˆ·å¿…é¡»å›ç­”
            print("\nğŸ’¬ è¯·æ ¹æ®ä»¥ä¸Šé—®é¢˜è¡¥å……ä¿¡æ¯ï¼ˆå¤šè¡Œè¾“å…¥ï¼Œç©ºè¡Œç»“æŸï¼Œè¾“å…¥exitå¯ç»ˆæ­¢ï¼‰ï¼š")
            user_input = self._get_user_input().strip()

            if not user_input:
                logger.warning("âš ï¸ ç”¨æˆ·æœªæä¾›è¡¥å……ä¿¡æ¯ï¼Œå°†åŸºäºç°æœ‰ä¿¡æ¯ç”Ÿæˆ")
            elif user_input.lower() in {"exit", "quit", "q", "åœæ­¢", "é€€å‡º"}:
                return {
                    "status": "error",
                    "message": "ç”¨æˆ·ç»ˆæ­¢å¯¹è¯",
                    "conversation": conversation_history
                }
            else:
                user_notes.append(user_input)
                conversation_history.append({
                    "role": "user",
                    "content": user_input,
                    "name": "User"
                })

            # ç¬¬1ã€2ã€3è½®ï¼šåŸºäºç”¨æˆ·å›ç­”ç»§ç»­åˆ†æï¼ˆåªæœ‰ä¸å®Œæ•´æ‰è¾“å‡ºï¼‰
            for round_idx in range(1, self.max_rounds + 1):  # round_idx: 1, 2, 3
                # æ„å»ºåˆ†ææç¤º
                merged_supplements = "\n".join(f"- {note}" for note in user_notes)
                analysis_prompt = self._prepare_initial_context(input_data, merged_supplements, asked_questions, is_first_round=False)
                
                print(f"\nğŸ”„ ç¬¬ {round_idx} è½®ï¼šåŸºäºç”¨æˆ·å›ç­”ç»§ç»­åˆ†æ")
                ai_response = await asyncio.to_thread(self._call_model, analysis_prompt, "analysis")
                ai_response = self._limit_text(ai_response, 300)
                info_complete = self._should_stop_questioning(ai_response)

                # æå–æœ¬æ¬¡æå‡ºçš„é—®é¢˜ï¼ŒåŠ å…¥è®°å¿†
                new_questions = self._extract_questions(ai_response)
                asked_questions.extend(new_questions)

                conversation_history.append({
                    "role": "assistant",
                    "content": ai_response,
                    "name": "SemanticReviewer"
                })

                # åªæœ‰åˆ¤æ–­ä¸ºä¸å®Œæ•´æ—¶æ‰è¾“å‡ºåˆ°ç»ˆç«¯
                if not info_complete:
                    print(f"\n{'=' * 60}")
                    print("ğŸ¤– AIåˆ†æç»“æœï¼š")
                    print(ai_response)
                    print(f"{'=' * 60}")

                    # å¦‚æœæ˜¯ç¬¬3è½®ï¼ˆround_idx == 3ï¼‰ï¼Œç”¨æˆ·å›ç­”åç›´æ¥ç”Ÿæˆï¼Œä¸å†å®¡æŸ¥
                    if round_idx == self.max_rounds:
                        print("\nâš ï¸ å·²è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ¬¡ï¼Œå°†åŸºäºç°æœ‰ä¿¡æ¯ç”ŸæˆåˆåŒèŒƒæœ¬")
                        break

                    # ç¬¬1ã€2è½®ç»§ç»­æé—®
                    print("\nğŸ’¬ è¯·æ ¹æ®ä»¥ä¸Šé—®é¢˜è¡¥å……ä¿¡æ¯ï¼ˆå¤šè¡Œè¾“å…¥ï¼Œç©ºè¡Œç»“æŸï¼Œè¾“å…¥exitå¯ç»ˆæ­¢ï¼‰ï¼š")
                    user_input = self._get_user_input().strip()

                    if not user_input:
                        logger.warning("âš ï¸ ç”¨æˆ·æœªæä¾›è¡¥å……ä¿¡æ¯ï¼Œå°†åŸºäºç°æœ‰ä¿¡æ¯ç”Ÿæˆ")
                        break

                    if user_input.lower() in {"exit", "quit", "q", "åœæ­¢", "é€€å‡º"}:
                        return {
                            "status": "error",
                            "message": "ç”¨æˆ·ç»ˆæ­¢å¯¹è¯",
                            "conversation": conversation_history
                        }

                    user_notes.append(user_input)
                    conversation_history.append({
                        "role": "user",
                        "content": user_input,
                        "name": "User"
                    })
                else:
                    # ä¿¡æ¯å®Œæ•´ï¼Œç›´æ¥ç”Ÿæˆ
                    print(f"\n{'=' * 60}")
                    print("âœ… ä¿¡æ¯å®Œæ•´ï¼Œå¼€å§‹ç”ŸæˆåˆåŒ")
                    print("[DEBUG] ğŸ¤– AIåˆ†æç»“æœï¼š")
                    print(ai_response)
                    print(f"{'=' * 60}")
                    break

            # æ— è®ºä¿¡æ¯æ˜¯å¦å®Œæ•´ï¼Œéƒ½ç”ŸæˆåˆåŒèŒƒæœ¬
            if info_complete:
                print("\nğŸ¯ ä¿¡æ¯å®Œæ•´ï¼Œå¼€å§‹ç”ŸæˆåˆåŒèŒƒæœ¬...")
            else:
                print("\nğŸ¯ åŸºäºç°æœ‰ä¿¡æ¯ç”ŸæˆåˆåŒèŒƒæœ¬ï¼ˆè¯·æ³¨æ„ï¼šæ­¤èŒƒæœ¬éœ€è¦è¿›ä¸€æ­¥ä¿®æ”¹å®Œå–„ï¼‰...")

            final_data = input_data.copy()
            if user_notes:
                final_data["user_supplements"] = "\n\n".join(user_notes)

            generation_prompt = self._build_generation_prompt(final_data)
            contract_content = await asyncio.to_thread(self._call_model, generation_prompt, "generation")

            conversation_history.append({
                "role": "assistant",
                "content": contract_content,
                "name": "ContractGenerator"
            })

            return {
                "status": "success",
                "contract": contract_content,
                "conversation": conversation_history,
                "message": "åˆåŒç”ŸæˆæˆåŠŸ"
            }

        except Exception as e:
            logger.error(f"âŒ åˆåŒå¤„ç†å¤±è´¥: {e}")
            raise

    def _get_user_input(self) -> str:
        """è·å–ç”¨æˆ·å¤šè¡Œè¾“å…¥ï¼ˆç©ºè¡Œç»“æŸï¼‰"""
        lines = []
        print("è¯·è¾“å…¥å†…å®¹ï¼ˆç©ºè¡Œç»“æŸï¼‰ï¼š")
        while True:
            try:
                line = input()
                if not line.strip():  # ç©ºè¡Œç»“æŸ
                    break
                lines.append(line)
            except EOFError:
                break
        return "\n".join(lines)

    def _limit_text(self, text: str, max_chars: int) -> str:
        """é™åˆ¶æ¨¡å‹è¾“å‡ºé•¿åº¦ï¼Œè¶…å‡ºéƒ¨åˆ†æˆªæ–­å¹¶æ ‡è®°"""
        if not text or len(text) <= max_chars:
            return text
        logger.warning(f"âš ï¸ æ¨¡å‹è¾“å‡ºé•¿åº¦è¶…è¿‡{max_chars}å­—ï¼Œå°†è‡ªåŠ¨æˆªæ–­")
        return text[:max_chars] + "..."

    def _should_stop_questioning(self, reviewer_message: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢æé—®"""
        if not reviewer_message:
            return False
        status = self._extract_status_tag(reviewer_message)
        if status == "å®Œæ•´":
            return True
        if status == "ä¸å®Œæ•´":
            return False

        normalized = reviewer_message.replace(" ", "")
        if "ä¸å®Œæ•´" in normalized or "æ— æ³•ç”Ÿæˆ" in normalized or "éœ€è¡¥å……" in normalized:
            return False
        if "ä¿¡æ¯å®Œæ•´" in normalized and "ä¸å®Œæ•´" not in normalized:
            return True
        if "å¯ä»¥ç”ŸæˆåˆåŒ" in normalized and "ä¸å¯ä»¥" not in normalized:
            return True
        return False

    def _extract_status_tag(self, reviewer_message: str) -> str:
        """è§£ææ¨¡å‹è¾“å‡ºä¸­çš„çŠ¶æ€æ ‡ç­¾"""
        if not reviewer_message:
            return ""
        match = re.search(r"ã€çŠ¶æ€ã€‘\s*(å®Œæ•´|ä¸å®Œæ•´)", reviewer_message)
        if match:
            return match.group(1)
        return ""

    def _extract_questions(self, ai_response: str) -> List[str]:
        """ä»AIå›ç­”ä¸­æå–æå‡ºçš„é—®é¢˜ï¼Œç”¨äºè®°å¿†é¿å…é‡å¤"""
        questions = []
        if not ai_response:
            return questions

        # å°è¯•ä»ã€é—®é¢˜ã€‘æ ‡ç­¾ä¸­æå–
        question_match = re.search(r"ã€é—®é¢˜ã€‘\s*([^\n]+(?:\n[^\n]+)*)", ai_response)
        if question_match:
            question_text = question_match.group(1).strip()
            # æŒ‰è¡Œåˆ†å‰²ï¼Œæ¯è¡Œä½œä¸ºä¸€ä¸ªé—®é¢˜
            for line in question_text.split('\n'):
                line = line.strip()
                if line and line != "æ— " and len(line) > 5:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                    questions.append(line)
        else:
            # å¦‚æœæ²¡æœ‰ã€é—®é¢˜ã€‘æ ‡ç­¾ï¼Œå°è¯•æå–é—®å·ç»“å°¾çš„å¥å­
            question_sentences = re.findall(r'[^ã€‚ï¼ï¼Ÿ]*[ï¼Ÿ?][^ã€‚ï¼ï¼Ÿ]*', ai_response)
            for q in question_sentences:
                q = q.strip()
                if q and len(q) > 5:
                    questions.append(q)

        return questions

    def _prepare_initial_context(self, input_data: Dict[str, Any], supplements: str = "", asked_questions: List[str] = None, is_first_round: bool = False) -> str:
        """å‡†å¤‡è¯­ä¹‰åˆ†æä¸Šä¸‹æ–‡"""
        if asked_questions is None:
            asked_questions = []

        context = """è¯·åˆ†æä»¥ä¸‹åˆåŒä¿¡æ¯çš„å®Œæ•´æ€§ï¼Œè¯†åˆ«ç¼ºå¤±æˆ–ä¸æ˜ç¡®çš„ä¿¡æ¯ã€‚æ³¨æ„ï¼šç”Ÿæˆçš„åˆåŒä»…ä¸ºèŒƒæœ¬ï¼Œéœ€è¦äººå·¥è¿›ä¸€æ­¥ä¿®æ”¹å®Œå–„ï¼Œå› æ­¤æœ‰ç‚¹ä¸¥æ ¼ä½†ä¸å¿…è¿‡äºä¸¥æ ¼ã€‚

    ã€åˆåŒåŸºæœ¬ä¿¡æ¯ã€‘
    """

        for key, value in input_data.items():
            if value:
                context += f"- {key}: {value}\n"

        if supplements:
            context += f"""
ã€ç”¨æˆ·æœ€æ–°è¡¥å……ã€‘
{supplements}
"""

        if asked_questions:
            context += f"""
ã€å·²æå‡ºçš„é—®é¢˜ï¼ˆè¯·å‹¿é‡å¤æé—®ï¼‰ã€‘
"""
            for i, q in enumerate(asked_questions, 1):
                context += f"{i}. {q}\n"

        # ç¬¬ä¸€è½®ç‰¹æ®Šæç¤ºï¼šå¿…é¡»åé—®
        if is_first_round:
            context += """
    ã€ç¬¬ä¸€è½®åˆ†æè¦æ±‚ï¼ˆé‡è¦ï¼‰ã€‘
    è¿™æ˜¯ç¬¬ä¸€è½®åˆ†æï¼Œå¿…é¡»æ‰¾å‡ºè‡³å°‘1-3ä¸ªé—®é¢˜å‘ç”¨æˆ·æé—®ï¼Œä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œæ•´ä½“å­—æ•°ä¸å¾—è¶…è¿‡300å­—ã€‚
    é‡ç‚¹å…³æ³¨ï¼š
    1. JSONä¸­æœªæåŠçš„å…³é”®ä¿¡æ¯ï¼ˆå¦‚ï¼šå…·ä½“äº¤ä»˜æ ‡å‡†ã€éªŒæ”¶æ ‡å‡†ã€ä¿å¯†æ¡æ¬¾ç­‰ï¼‰
    2. ä¿¡æ¯ä¸æ˜ç¡®çš„åœ°æ–¹ï¼ˆå¦‚ï¼šé‡‘é¢å•ä½ã€æ—¶é—´èŠ‚ç‚¹ã€è´£ä»»åˆ’åˆ†ç­‰ï¼‰
    3. å³ä½¿ä¿¡æ¯çœ‹èµ·æ¥å®Œæ•´ï¼Œä¹Ÿè¦æ‰¾å‡ºå¯ä»¥è¿›ä¸€æ­¥æ˜ç¡®æˆ–è¡¥å……çš„ç‚¹
    4. è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ï¼ˆç¦æ­¢æ·»åŠ å¤šä½™æ®µè½ï¼‰ï¼š
       ã€çŠ¶æ€ã€‘å®Œæ•´/ä¸å®Œæ•´ï¼ˆä»…å¯äºŒé€‰ä¸€ï¼‰å¯ä»¥ç”ŸæˆåˆåŒå¿…é¡»æ˜¾ç¤ºå®Œæ•´
       ã€ç»“è®ºã€‘ä¸€å¥è¯æ¦‚æ‹¬ç»“æœï¼Œè‹¥å®Œæ•´éœ€åŒ…å«"å¯ä»¥ç”ŸæˆåˆåŒ"
       ã€é—®é¢˜ã€‘è‹¥çŠ¶æ€ä¸ºä¸å®Œæ•´ï¼Œåˆ—å‡ºæ•°æ¡å¾…è¡¥å……é—®é¢˜ï¼›è‹¥çŠ¶æ€ä¸ºå®Œæ•´ï¼Œå¡«å†™"æ— "
    é™¤éä¿¡æ¯çœŸçš„éå¸¸å®Œæ•´ä¸”æ— ä»»ä½•å¯ä¼˜åŒ–ç©ºé—´ï¼Œå¦åˆ™å¿…é¡»æé—®ã€‚
    """

        context += """
    è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚åˆ†æå¹¶è¾“å‡ºï¼Œæ•´ä½“å­—æ•°ä¸å¾—è¶…è¿‡300å­—ï¼š
    1. åˆ¤æ–­å…³é”®ä¿¡æ¯æ˜¯å¦åŸºæœ¬å®Œå–„ï¼Œæ³¨æ„è¿™æ˜¯åˆåŒèŒƒæœ¬ï¼Œä¸éœ€è¦100%å®Œæ•´
    2. è‹¥å­˜åœ¨ç¼ºå¤±æˆ–ä¸æ˜ç¡®ä¿¡æ¯ï¼Œä»…åˆ—å‡ºæœ€å…³é”®çš„æ•°æ¡é—®é¢˜ï¼ˆé¿å…é‡å¤å·²é—®è¿‡çš„é—®é¢˜ï¼‰
    3. è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ï¼ˆç¦æ­¢æ·»åŠ å¤šä½™æ®µè½ï¼‰ï¼š
       ã€çŠ¶æ€ã€‘å®Œæ•´/ä¸å®Œæ•´ï¼ˆä»…å¯äºŒé€‰ä¸€ï¼‰å¯ä»¥ç”ŸæˆåˆåŒå¿…é¡»æ˜¾ç¤ºå®Œæ•´
       ã€ç»“è®ºã€‘ä¸€å¥è¯æ¦‚æ‹¬ç»“æœï¼Œè‹¥å®Œæ•´éœ€åŒ…å«"å¯ä»¥ç”ŸæˆåˆåŒ"
       ã€é—®é¢˜ã€‘è‹¥çŠ¶æ€ä¸ºä¸å®Œæ•´ï¼Œåˆ—å‡ºæ•°æ¡å¾…è¡¥å……é—®é¢˜ï¼›è‹¥çŠ¶æ€ä¸ºå®Œæ•´ï¼Œå¡«å†™"æ— "
    4. è¦æ±‚å…³é”®è¦ç´ ï¼ˆä¸»ä½“ã€æœåŠ¡å†…å®¹ã€é‡‘é¢/æ”¯ä»˜ã€æœŸé™ç­‰ï¼‰åŸºæœ¬æ˜ç¡®"
    5. ä¸å…è®¸è¾“å‡ºjsonçš„å­—æ®µï¼Œå³é”®å€¼å¯¹çš„é”®ï¼Œæ¶‰åŠä¹Ÿä¸å…è®¸ï¼ï¼ï¼ï¼
    6. ä¸¥ç¦é‡å¤æå‡ºå·²åˆ—åœ¨"å·²æå‡ºçš„é—®é¢˜"ä¸­çš„ç›¸åŒæˆ–ç±»ä¼¼é—®é¢˜"""

        if is_first_round:
            context += """
    7. ã€ç¬¬ä¸€è½®å¼ºåˆ¶è¦æ±‚ã€‘å¿…é¡»æ‰¾å‡ºè‡³å°‘1-3ä¸ªé—®é¢˜ï¼Œé™¤éä¿¡æ¯çœŸçš„éå¸¸å®Œæ•´ä¸”æ— ä»»ä½•å¯ä¼˜åŒ–ç©ºé—´"""

        context += """

    è¯·å¼€å§‹åˆ†æï¼š"""

        return context

    def _build_generation_prompt(self, input_data: Dict[str, Any]) -> str:
        """æ„å»ºåˆåŒç”Ÿæˆæç¤ºè¯"""
        contract_type = input_data.get('contract_type', '').lower()
        template_key = self._select_template(contract_type)
        template_content = self.templates.get(template_key, "")

        prompt = f"""è¯·åŸºäºä»¥ä¸‹å®Œæ•´ä¿¡æ¯ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„åˆåŒèŒƒæœ¬ï¼š

ã€åˆåŒä¿¡æ¯ã€‘
{json.dumps(input_data, ensure_ascii=False, indent=2)}"""

        if template_content:
            prompt += f"""

ã€å‚è€ƒæ¨¡æ¿æ ¼å¼ã€‘
{template_content}

**é‡è¦**ï¼šå‚è€ƒæ¨¡æ¿çš„ç»“æ„å’Œæ¡æ¬¾ç±»å‹ï¼Œä½†ä¸è¦ç›´æ¥å¤åˆ¶æ¨¡æ¿å†…å®¹ã€‚åŸºäºæä¾›çš„å…·ä½“ä¿¡æ¯ç”Ÿæˆå…¨æ–°çš„åˆåŒå†…å®¹ã€‚"""

        prompt += """

**ç”Ÿæˆè¦æ±‚**ï¼š
1. åœ¨åˆåŒå¼€å¤´å¿…é¡»æ·»åŠ ä»¥ä¸‹å£°æ˜ï¼ˆä½¿ç”¨é†’ç›®æ ‡è®°ï¼‰ï¼š
   "---
   ã€é‡è¦æç¤ºã€‘æœ¬åˆåŒç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¸ºå‚è€ƒèŒƒæœ¬ï¼Œå¿…é¡»ç»è¿‡ä¸“ä¸šæ³•å¾‹äººå‘˜å®¡æ ¸å’Œä¿®æ”¹åæ–¹å¯ä½¿ç”¨ã€‚ä¸å¾—ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™å¯èƒ½äº§ç”Ÿæ³•å¾‹é£é™©ã€‚
   ---"
2. åŸºäºæä¾›çš„å…·ä½“ä¿¡æ¯ç”ŸæˆåˆåŒå†…å®¹
3. æ¡æ¬¾å®Œæ•´ã€åˆæ³•ã€ä¸“ä¸š
4. ä½¿ç”¨è§„èŒƒçš„åˆåŒè¯­è¨€
5. åŒ…å«å¿…è¦çš„åˆåŒè¦ç´ 
6. è¾“å‡ºçº¯åˆåŒå†…å®¹ï¼ˆåŒ…å«å¼€å¤´çš„å£°æ˜ï¼‰ï¼Œä¸è¦åŒ…å«é¢å¤–è¯´æ˜

è¯·ç”ŸæˆåˆåŒï¼š"""

        return prompt

    def _select_template(self, contract_type: str) -> str:
        """é€‰æ‹©åˆåŒæ¨¡æ¿"""
        for key in self.templates.keys():
            if key in contract_type or contract_type in key:
                return key
        return 'default'

    def _load_contract_templates(self):
        """åŠ è½½åˆåŒæ¨¡æ¿ - æ‰¾ä¸åˆ°æ¨¡æ¿ç›´æ¥æŠ¥é”™"""
        # åˆå§‹åŒ–æ¨¡æ¿ç›®å½•
        current_dir = Path(__file__).parent
        self.template_dir = current_dir.parent / "templates"
        self.templates = {}

        logger.info(f"ğŸ“ æŸ¥æ‰¾æ¨¡æ¿ç›®å½•: {self.template_dir}")

        if not self.template_dir.exists():
            error_msg = f"âŒ æ¨¡æ¿ç›®å½•ä¸å­˜åœ¨: {self.template_dir}"
            logger.error(error_msg)
            raise FileNotFoundError(error_msg)

        template_files = list(self.template_dir.glob("*.md"))

        if not template_files:
            error_msg = f"âŒ æ¨¡æ¿ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•.mdæ¨¡æ¿æ–‡ä»¶: {self.template_dir}"
            logger.error(error_msg)
            raise FileNotFoundError(error_msg)

        logger.info(f"ğŸ” æ‰¾åˆ° {len(template_files)} ä¸ªæ¨¡æ¿æ–‡ä»¶")

        # åŠ è½½æ‰€æœ‰æ¨¡æ¿æ–‡ä»¶
        for template_file in template_files:
            try:
                with open(template_file, 'r', encoding='utf-8') as f:
                    self.templates[template_file.stem] = f.read()
                logger.info(f"âœ… åŠ è½½æ¨¡æ¿: {template_file.name}")
            except Exception as e:
                error_msg = f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥ {template_file.name}: {e}"
                logger.error(error_msg)
                raise Exception(error_msg)

        logger.info(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(self.templates)} ä¸ªæ¨¡æ¿: {list(self.templates.keys())}")



    def run(self):
        """è¿è¡Œæ¼”ç¤ºä¸»å‡½æ•°ï¼ˆåŒæ­¥å…¥å£ï¼Œå†…éƒ¨è°ƒç”¨å¼‚æ­¥é€»è¾‘ï¼‰"""
        # ç”¨asyncio.run()åŒ…è£¹å¼‚æ­¥æ ¸å¿ƒé€»è¾‘
        asyncio.run(self._async_run())

    async def _async_run(self):
        """å¼‚æ­¥æ ¸å¿ƒä¸»å‡½æ•°ï¼ˆäº¤äº’å¼å¤„ç†æ¨¡å¼ï¼‰"""
        try:
            logger.info("ğŸš€ å¯åŠ¨åˆåŒç”Ÿæˆæ¼”ç¤ºç¨‹åº")
            print("=" * 70)
            print("ğŸ¤– æ™ºèƒ½åˆåŒç”Ÿæˆç³»ç»Ÿï¼ˆäº¤äº’å¼æ¨¡å¼ï¼‰")
            print("=" * 70)

            # è®¾ç½®è·¯å¾„
            current_dir = Path(__file__).parent
            input_dir = current_dir.parent / "input"

            logger.info(f"ğŸ” æŸ¥æ‰¾inputç›®å½•: {input_dir}")
            print(f"ğŸ” æŸ¥æ‰¾inputç›®å½•: {input_dir}")

            if not input_dir.exists():
                logger.error(f"âŒ inputç›®å½•ä¸å­˜åœ¨: {input_dir}")
                print(f"âŒ é”™è¯¯: inputç›®å½•ä¸å­˜åœ¨")
                return

            json_files = list(input_dir.glob("*.json"))
            if not json_files:
                logger.warning(f"âš ï¸ inputç›®å½•ä¸­æ²¡æœ‰JSONæ–‡ä»¶: {input_dir}")
                print(f"âŒ é”™è¯¯: inputç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
                return

            print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªåˆåŒæ–‡ä»¶:")
            for i, json_file in enumerate(json_files, 1):
                print(f"  {i}. {json_file.name}")

            # äº¤äº’å¼å¤„ç†ï¼šé€ä¸ªæ–‡ä»¶å¤„ç†
            print(f"\n{'=' * 70}")
            print("ğŸ” äº¤äº’å¼å¤„ç†æ¨¡å¼")
            print(f"{'=' * 70}")

            for i, json_file in enumerate(json_files, 1):
                print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(json_files)}: {json_file.name}")

                with open(json_file, 'r', encoding='utf-8') as f:
                    input_data = json.load(f)

                print(f"ğŸ“‹ åˆå§‹ä¿¡æ¯:")
                for key, value in input_data.items():
                    print(f"  - {key}: {value}")

                # å¼‚æ­¥æ–¹æ³•åŠ await
                result = await self.process_contract_interactive(input_data)

                if result['status'] == 'success':
                    output_dir = current_dir.parent / "output"
                    output_dir.mkdir(exist_ok=True)
                    output_file = output_dir / f"{json_file.stem}.md"

                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(result['contract'])

                    print(f"âœ… åˆåŒå·²ä¿å­˜: {output_file}")
                    print(f"ğŸ“„ åˆåŒé¢„è§ˆ:\n{result['contract'][:300]}...")
                else:
                    print(f"âŒ ç”Ÿæˆå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

                if i < len(json_files):
                    continue_choice = input(f"\nç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶? (y/n): ").strip().lower()
                    if continue_choice != 'y':
                        break

            print(f"\n{'=' * 70}")
            print("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ")
            print(f"{'=' * 70}")

        except Exception as e:
            logger.error(f"âŒ æ¼”ç¤ºç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        finally:
            self.release_resources()

    def release_resources(self):
        """é‡Šæ”¾æ¨¡å‹èµ„æº"""
        if self.local_model and self.local_model.is_loaded():
            self.local_model.release_resources()
            logger.info("âœ… å·²é‡Šæ”¾æœ¬åœ°æ¨¡å‹èµ„æº")
        if hasattr(self, "http_session") and self.http_session:
            try:
                self.http_session.close()
                logger.debug("ğŸ§¹ HTTPä¼šè¯å·²å…³é—­")
            except Exception:
                pass

    def __del__(self):
        """ææ„å‡½æ•°"""
        self.release_resources()


if __name__ == "__main__":
    # é…ç½®è¯¦ç»†æ—¥å¿—
    logger.remove()
    logger.add(
        "contract_system.log",
        level="DEBUG",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {file}:{line} | {message}",
        rotation="10 MB",
        retention="7 days"
    )
    logger.add(
        sys.stdout,
        level="DEBUG",
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>"
    )

    # è¿è¡Œæ¼”ç¤ºç¨‹åº
    manager = ContractManager()
    manager.run()